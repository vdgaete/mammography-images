{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esse notebook tem como objetivo realizar o pré-processamento dos dados do CBIS-DDSM\n",
    "# carrergando as imagens com o seu respectivo label e salvando em um arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis de ambiente\n",
    "# ---------------------\n",
    "# - DATA_PATH: caminho para os dados\n",
    "# C:\\Users\\{home}\\Data\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pydicom\n",
    "import glob \n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import image contrast enhancement\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "# This notebook want to import the CBIS-DDSM dataset\n",
    "# make a subset of the dataset for fast training and testing\n",
    "# and save the subset in a new folder\n",
    "# the subset will be used in the next notebooks\n",
    "# the subset will be composed by 2 folders: train and test\n",
    "# each folder will have 2 subfolders: benign and malignant\n",
    "# each subfolder will have the images of the respective class\n",
    "\n",
    "# The dataset is available at: CBISDDSM_PATH\n",
    "\n",
    "home_directory = os.path.expanduser( '~' )\n",
    "DATA_PATH = os.path.join( home_directory, 'Data')\n",
    "# CBIS-DDSM\n",
    "CBISDDSM_PATH = os.path.join( DATA_PATH, 'CBIS-DDSM')\n",
    "\n",
    "CALC_TEST_PATH = os.path.join( CBISDDSM_PATH, 'CALC-TEST' )\n",
    "CALC_TRAIN_PATH = os.path.join( CBISDDSM_PATH, 'CALC-TRAIN' )\n",
    "# in CBIS-DDSM there are 2 folder for CALC\n",
    "# and 2 folders for MASS\n",
    "# each folder has the images and the metadata\n",
    "\n",
    "# the metadata are in DICOM format\n",
    "# the images are in dcm format\n",
    "\n",
    "# the metadata are in the root of the folder\n",
    "# the images are in subfolders in CBIS-DDSM\n",
    "\n",
    "# import train and test metadata\n",
    "\n",
    "# metadata for CALC\n",
    "train_calc = pd.read_csv( os.path.join( CBISDDSM_PATH, 'CALC-TRAIN', 'metadata.csv' ) )\n",
    "test_calc = pd.read_csv( os.path.join( CBISDDSM_PATH, 'CALC-TEST', 'metadata.csv' ) )\n",
    "\n",
    "# Annotation file for CALC\n",
    "train_calc_annotations = pd.read_csv( os.path.join( CBISDDSM_PATH, 'calc_case_description_train_set.csv' ) )\n",
    "test_calc_annotations = pd.read_csv( os.path.join( CBISDDSM_PATH, 'calc_case_description_test_set.csv' ) )\n",
    "\n",
    "train_calc_annotations['Case'] = train_calc_annotations['ROI mask file path'].apply( lambda x: x.split('/')[-2] )\n",
    "\n",
    "case_objects = []\n",
    "\n",
    "for index, row in train_calc_annotations.iterrows():\n",
    "\n",
    "    # get the case\n",
    "    case = row['Case']\n",
    "    # get the objects that the case is equal to the index\n",
    "    \n",
    "    case_objects.append(train_calc[train_calc.index.values == case]['File Location'].values[0])\n",
    "\n",
    "#add \\\\ to the path\n",
    "case_objects = [x.replace('/', '\\\\') for x in case_objects]\n",
    "case_objects = [x[2:] for x in case_objects]\n",
    "# add CALC-TRAIN to the path\n",
    "case_objects = [os.path.join( CALC_TRAIN_PATH, x ) for x in case_objects]\n",
    "# add \\\\ to the end of the path\n",
    "case_objects = [x + '\\\\' for x in case_objects]\n",
    "\n",
    "# list number of files\n",
    "# for each case\n",
    "# and add to the dataframe\n",
    "file_cases = []\n",
    "for case in case_objects:\n",
    "    files = glob.glob(case + '**\\\\*.dcm', recursive=True)\n",
    "    file_cases.append(files)\n",
    "\n",
    "# each case has 2 files\n",
    "# one for the ROI mask\n",
    "# and one for the cropped image\n",
    "# we will use the cropped image\n",
    "\n",
    "# identify the cropped image\n",
    "# and remove the ROI mask\n",
    "# from the list of files\n",
    "cropped_files = []\n",
    "# the cropped image has the least size\n",
    "# so we will use this to identify the cropped image\n",
    "for files in file_cases:\n",
    "    sizes = []\n",
    "    for file in files:\n",
    "        sizes.append(os.path.getsize(file))\n",
    "    cropped_files.append(files[np.argmin(sizes)])\n",
    "\n",
    "# add the cropped files to the dataframe\n",
    "train_calc_annotations['cropped_file'] = cropped_files\n",
    "\n",
    "# delete columns that are not necessary\n",
    "train_calc_annotations.drop(columns=['ROI mask file path','image file path'], inplace=True)\n",
    "train_calc_annotations.head()\n",
    "\n",
    "# do the same for test\n",
    "# Annotation file for CALC\n",
    "test_calc_annotations = pd.read_csv( os.path.join( CBISDDSM_PATH, 'calc_case_description_test_set.csv' ) )\n",
    "\n",
    "test_calc_annotations['Case'] = test_calc_annotations['ROI mask file path'].apply( lambda x: x.split('/')[-2] )\n",
    "\n",
    "case_objects = []\n",
    "\n",
    "for index, row in test_calc_annotations.iterrows():\n",
    "    \n",
    "        # get the case\n",
    "        case = row['Case']\n",
    "        # get the objects that the case is equal to the index\n",
    "        \n",
    "        case_objects.append(test_calc[test_calc.index.values == case]['File Location'].values[0])\n",
    "\n",
    "#add \\\\ to the path\n",
    "case_objects = [x.replace('/', '\\\\') for x in case_objects]\n",
    "case_objects = [x[2:] for x in case_objects]\n",
    "# add CALC-TRAIN to the path\n",
    "case_objects = [os.path.join( CALC_TEST_PATH, x ) for x in case_objects]\n",
    "# add \\\\ to the end of the path\n",
    "case_objects = [x + '\\\\' for x in case_objects]\n",
    "\n",
    "# list number of files\n",
    "# for each case\n",
    "# and add to the dataframe\n",
    "file_cases = []\n",
    "for case in case_objects:\n",
    "    files = glob.glob(case + '**\\\\*.dcm', recursive=True)\n",
    "    file_cases.append(files)\n",
    "\n",
    "# each case has 2 files\n",
    "# one for the ROI mask\n",
    "# and one for the cropped image\n",
    "# we will use the cropped image\n",
    "\n",
    "# identify the cropped image\n",
    "# and remove the ROI mask\n",
    "# from the list of files\n",
    "cropped_files = []\n",
    "# the cropped image has the least size\n",
    "# so we will use this to identify the cropped image\n",
    "for files in file_cases:\n",
    "    sizes = []\n",
    "    for file in files:\n",
    "        sizes.append(os.path.getsize(file))\n",
    "    cropped_files.append(files[np.argmin(sizes)])\n",
    "\n",
    "# add the cropped files to the dataframe\n",
    "test_calc_annotations['cropped_file'] = cropped_files\n",
    "\n",
    "# delete columns that are not necessary\n",
    "test_calc_annotations.drop(columns=['ROI mask file path', 'cropped image file path', 'image file path'], inplace=True)\n",
    "test_calc_annotations.head()\n",
    "\n",
    "# save the annotations in a csv file\n",
    "train_calc_annotations.to_csv('train_calc_annotations.csv', index=False)\n",
    "test_calc_annotations.to_csv('test_calc_annotations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
