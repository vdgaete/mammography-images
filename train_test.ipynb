{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded...\n",
      "labels converted...\n",
      "Data Format:\n",
      "(1446, 224, 224, 3)\n",
      "(1446, 2)\n",
      "(100, 224, 224, 3)\n",
      "(100, 2)\n",
      "(326, 224, 224, 3)\n",
      "(326, 2)\n"
     ]
    }
   ],
   "source": [
    "# now we will test our model on test data\n",
    "# first we train our model on train data without any preprocessing\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import cv2\n",
    "import pydicom\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('train_calc_annotations2.csv')\n",
    "test = pd.read_csv('test_calc_annotations2.csv')\n",
    "\n",
    "# create train and test data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# print\n",
    "print('Loading data...')\n",
    "\n",
    "for i in range(len(train)):\n",
    "    # load dicom images\n",
    "    image = pydicom.dcmread(train['cropped_file'][i]).pixel_array\n",
    "    # resize images\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # normalize images\n",
    "    image = image / 255.0\n",
    "    # make 3 channels\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    # append data\n",
    "    train_data.append(image)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # load dicom images\n",
    "    image = pydicom.dcmread(test['cropped_file'][i]).pixel_array\n",
    "    # resize images\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # normalize images\n",
    "    image = image / 255.0\n",
    "    # make 3 channels\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    # append data\n",
    "    test_data.append(image)\n",
    "\n",
    "print('Data loaded...')\n",
    "\n",
    "# convert data into numpy array\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "# create train and test labels\n",
    "train_labels = train['pathology'].values\n",
    "test_labels = test['pathology'].values\n",
    "\n",
    "# list possible labels\n",
    "labels = ['BENIGN', 'MALIGNANT']\n",
    "\n",
    "# if label is BENIGN_WITHOUT_CALLBACK then convert it into BENIGN\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 'BENIGN_WITHOUT_CALLBACK':\n",
    "        train_labels[i] = 'BENIGN'\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 'BENIGN_WITHOUT_CALLBACK':\n",
    "        test_labels[i] = 'BENIGN'\n",
    "\n",
    "\n",
    "# convert labels into int values\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 'BENIGN':\n",
    "        train_labels[i] = 0\n",
    "    else:\n",
    "        train_labels[i] = 1\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 'BENIGN':\n",
    "        test_labels[i] = 0\n",
    "    else:\n",
    "        test_labels[i] = 1\n",
    "\n",
    "    \n",
    "\n",
    "# convert labels into categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(\"labels converted...\")\n",
    "\n",
    "# create internal validation data\n",
    "val_data = train_data[:100]\n",
    "val_labels = train_labels[:100]\n",
    "\n",
    "# create train data\n",
    "train_data = train_data[100:]\n",
    "train_labels = train_labels[100:]\n",
    "\n",
    "print('Data Format:')\n",
    "# print shapes\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_data.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 16:19:55.983439: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:55.984508: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.000294: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.001189: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.015735: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.016765: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.053862: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-14 16:19:56.055088: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_51934/910059373.py\", line 59, in <module>\n      history = model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20,\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_3'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node Adam/StatefulPartitionedCall_3}}]] [Op:__inference_train_function_36273]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb Célula 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m datagen \u001b[39m=\u001b[39m ImageDataGenerator(horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, vertical_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, rotation_range\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, zoom_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m                              width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, height_shift_range\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, shear_range\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(datagen\u001b[39m.\u001b[39;49mflow(train_data, train_labels, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                               validation_data\u001b[39m=\u001b[39;49m(val_data, val_labels), callbacks\u001b[39m=\u001b[39;49m[early_stopping, reduce_lr])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# save model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vdgaete-pc/TCC/mammography-images/train_test.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mresnet50.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-images/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_51934/910059373.py\", line 59, in <module>\n      history = model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20,\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/vdgaete-pc/anaconda3/envs/ml-images/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_3'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node Adam/StatefulPartitionedCall_3}}]] [Op:__inference_train_function_36273]"
     ]
    }
   ],
   "source": [
    "# train resnet50 model\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# set device to gpu\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "\n",
    "# load resnet50 model\n",
    "resnet50 = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# freeze layers\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add layers\n",
    "x = resnet50.output\n",
    "# flatten layer\n",
    "# convert 3d to 1d\n",
    "x = Flatten()(x)\n",
    "# add dense layer\n",
    "# 512 neurons\n",
    "# relu activation\n",
    "# dense layer is fully connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# add dropout\n",
    "# to avoid overfitting\n",
    "x = Dropout(0.5)(x)\n",
    "# output layer\n",
    "# 3 neurons\n",
    "# softmax activation\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "# each neuron will give probability of each class\n",
    "# class with highest probability will be the output\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=resnet50.input, outputs=output)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.003), metrics=['accuracy'])\n",
    "\n",
    "# create callbacks\\\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=30, zoom_range=0.2,\n",
    "                             width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20,\n",
    "                              validation_data=(val_data, val_labels), callbacks=[early_stopping, reduce_lr])\n",
    "# save model\n",
    "model.save('resnet50.h5')\n",
    "\n",
    "# plot accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "# predict test data\n",
    "predictions = model.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(np.argmax(test_labels, axis=1), predictions))\n",
    "\n",
    "# print confusion matrix\n",
    "print(confusion_matrix(np.argmax(test_labels, axis=1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train vgg16 model\n",
    "# load vgg16 model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# freeze layers\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add layers\n",
    "x = vgg16.output\n",
    "# flatten layer\n",
    "x = Flatten()(x)\n",
    "# add dense layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# add dropout\n",
    "x = Dropout(0.5)(x)\n",
    "# output layer\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=vgg16.input, outputs=output)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# load model\n",
    "model = load_model('vgg16.h5')\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=30, zoom_range=0.2,\n",
    "                             width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20,\n",
    "                              validation_data=(val_data, val_labels), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# save model\n",
    "model.save('vgg16.h5')\n",
    "\n",
    "# plot accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'])\n",
    "\n",
    "# predict test data\n",
    "predictions = model.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(np.argmax(test_labels, axis=1), predictions))\n",
    "\n",
    "# print confusion matrix\n",
    "print(confusion_matrix(np.argmax(test_labels, axis=1), predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train inceptionv3 model\n",
    "# load inceptionv3 model\n",
    "inceptionv3 = InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# freeze layers\n",
    "for layer in inceptionv3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add layers\n",
    "x = inceptionv3.output\n",
    "# flatten layer\n",
    "x = Flatten()(x)\n",
    "# add dense layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# add dropout\n",
    "x = Dropout(0.5)(x)\n",
    "# output layer\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# load model\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=30, zoom_range=0.2,\n",
    "                             width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20,\n",
    "                              validation_data=(val_data, val_labels), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# save model\n",
    "model.save('inceptionv3.h5')\n",
    "\n",
    "# plot accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "# predict test data\n",
    "predictions = model.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(np.argmax(test_labels, axis=1), predictions))\n",
    "\n",
    "# print confusion matrix\n",
    "print(confusion_matrix(np.argmax(test_labels, axis=1), predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
